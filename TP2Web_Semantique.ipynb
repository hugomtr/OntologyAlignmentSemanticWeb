{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP2Web_Semantique.ipynb","provenance":[],"collapsed_sections":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Installing missing packages & Loading"],"metadata":{"id":"GOOCjGyMFGkG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4hU6I-YXHlP"},"outputs":[],"source":["!pip install rdflib"]},{"cell_type":"code","source":["#!pip install kglab\n","!pip install textdistance\n","!pip install textdistance[extras]\n","!pip install deep_translator"],"metadata":{"id":"wb3KRHAVdxT8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys"],"metadata":{"id":"mudBd3woZpr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdflib import Graph\n","from rdflib import URIRef\n","from rdflib.namespace import RDF\n","import random \n","import numpy as np\n","import textdistance as td\n","import itertools    \n","import collections"],"metadata":{"id":"Xsexm5awcNsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"metadata":{"id":"pGDQdlriZU4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_local_drive='/content/gdrive/My Drive/Colab Notebooks/WebSemantique'\n","# Ajout du path pour les librairies, fonctions et données\n","sys.path.append(my_local_drive)\n","# Se positionner sur le répertoire associé\n","%cd $my_local_drive\n","\n","%pwd"],"metadata":{"id":"pjKa6SpSZbwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_graph = Graph()\n","target_graph.parse('target.ttl', format='ttl')\n","np_arr_target = np.array(target_graph).astype(\"str\")"],"metadata":{"id":"gBrGLcS1X04w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["source_graph = Graph()\n","source_graph.parse('source.ttl', format='ttl')\n","np_arr_source = np.array(source_graph).astype(\"str\")"],"metadata":{"id":"DMc9R_0AlRVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all_subject_source = np.unique(np_arr_source[:,0])\n","# all_subject_target = np.unique(np_arr_target[:,0])\n","# all_pred_source = np.unique(np_arr_source[:,1])\n","# all_pred_target = np.unique(np_arr_target[:,1])\n","# all_object_source = np.unique(np_arr_source[:,2])\n","# all_object_target = np.unique(np_arr_target[:,2])"],"metadata":{"id":"lKyRcV62dJ4q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"UDydU0Btc1MX"}},{"cell_type":"code","source":["import re\n","import nltk\n","import copy as cp\n","from deep_translator import GoogleTranslator\n","from nltk import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from nltk import RegexpParser\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","\n","stopwords = np.array(nltk.corpus.stopwords.words('english'))"],"metadata":{"id":"7EINwSC2gXrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# getting rid of all nodes objects\n","rNode = re.compile('^n[0-9]*.*')\n","\n","# getting rid of all url objects\n","rURL = re.compile(\"http://.*\")\n","\n","idx_to_keep_source = [i for i in range(len(np_arr_source[:,2])) if not (bool(rNode.match(np_arr_source[i,2])) or \n","                                                                        bool(rURL.match(np_arr_source[i,2])))] \n","idx_to_keep_target = [i for i in range(len(np_arr_target[:,2])) if not bool(rNode.match(np_arr_target[i,2])) or \n","                                                                           not bool(rURL.match(np_arr_target[i,2]))]"],"metadata":{"id":"rl84-5B7HCXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We avoid to change the main array of reference and by this use a copy\n","np_source_cp = cp.deepcopy(np_arr_source)\n","np_target_cp = cp.deepcopy(np_arr_target)\n","objet_source = np_source_cp[idx_to_keep_source,2]\n","objet_target = np_target_cp[idx_to_keep_target,2]"],"metadata":{"id":"vAQKSJs45uYK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translate(np_array):\n","  for i,s in zip(range(len(np_array)),np_array):\n","    try:\n","      np_array[i] = GoogleTranslator(source='auto', target='fr').translate(s)\n","    except:\n","      pass\n","    finally:\n","      pass\n","  return np_array\n","\n","def preprocess(np_array):\n","  for i,sentence in zip(range(len(np_array)),np_array):\n","    # Removing punctuation\n","    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n","    sentence = tokenizer.tokenize(sentence)\n","\n","    sentence = \" \".join(sentence)\n","    sentence = word_tokenize(sentence)\n","\n","    # Removing word with only one letter\n","    sentence = [word for word in sentence if len(word) != 1]\n","\n","    # converting each word to lowercase\n","    sentence = [word.lower() for word in sentence]\n","\n","    # Removing stopwords\n","    sentence = [word for word in sentence if not word in stopwords]\n","\n","    # lemmatizer words \n","    lemmatizer = WordNetLemmatizer()\n","    sentence = [lemmatizer.lemmatize(word) for word in sentence]\n","    \n","    # Removing pronouns infinitive verbs dt...\n","    for word in nltk.pos_tag(sentence):\n","      word_to_keep = []\n","      if word[1] not in ['IN', 'PP', 'DT','PRP$','VB','MD']:\n","        word_to_keep.append(word[0])\n","\n","    sentence = (\" \").join(sentence)\n","    np_array[i] = sentence\n","  return np_array\n","\n","objet_source = translate(objet_source)\n","objet_target = translate(objet_target)\n","\n","objet_source = preprocess(objet_source)\n","objet_target = preprocess(objet_target)\n"],"metadata":{"id":"DNSQyd_Z5xME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["objet_source[100:1000]"],"metadata":{"id":"vBDD-cMnYM4E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# URI Comparaison"],"metadata":{"id":"yoGVzbHFrvWb"}},{"cell_type":"code","source":["all_subject_source = np_arr_source[:,0]\n","all_subject_target = np_arr_target[:,0]"],"metadata":{"id":"D1VY_fcVubXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all subjects which have the same URI in the source RDF graph and in the target one\n","same_uri_list = np.intersect1d(all_subject_source,all_subject_target)\n"],"metadata":{"id":"1afielO_u6yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["objects = [x[2] for x in np_arr_target if x[0] in same_uri_list]\n","np.unique(objects)\n","# it seems like all the uri find identified the same 'thing'"],"metadata":{"id":"pnADbs6fvMnL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# <Predicate, Value> Comparaison"],"metadata":{"id":"DIwDedELvhuN"}},{"cell_type":"code","source":["subject = \"http://data.doremus.org/event/25096a99-08f3-33e3-a441-031623040855\""],"metadata":{"id":"I-V8QIn5ocQR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np_arr_source[np_arr_source[:,0] == subject][:,1]"],"metadata":{"id":"NSBN8WKiVRRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_prop_with_occurence(np_graph):\n","  \"\"\"\n","  retourne toutes les propriétés avec leurs occurences respectives pour un graphe rdf donné\n","  \"\"\"\n","  dico = collections.Counter(x for x in np_graph[:,1])\n","  return {k: v for k, v in sorted(dico.items(), key=lambda item: item[1],reverse = True)}\n","\n","# list of property ranked by occurence\n","\n","prop_source = list(find_prop_with_occurence(np_arr_source).keys())\n","prop_target = list(find_prop_with_occurence(np_arr_target).keys())\n","prop_union = np.intersect1d(prop_source,prop_source)"],"metadata":{"id":"h_S3JBCk3dBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# retourne tous les propriétés associès à un sujet\n","f = lambda subject : np_arr_source[np_arr_source[:,0] == subject][:,1:]\n","\n","source_prop_subject = list()\n","for subject in all_subject_source:\n","  source_prop_subject.append(f(subject))\n","\n","f = lambda subject : np_arr_source[np_arr_source[:,0] == subject][:,1:]\n","\n","target_prop_subject = list()\n","for subject in all_subject_source:\n","  target_prop_subject.append(f(subject))"],"metadata":{"id":"L9yDlSBkt5qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# choosing propertys given id based on rank of occurency\n","prop_ids = [1,4]\n","# property corresponding\n","prop_union[prop_ids]"],"metadata":{"id":"t4fjhLVOafo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# select all subject which have one this property\n","triplet_from_source = np_arr_source[np_arr_source[:,1] == \"http://erlangen-crm.org/current/P102_has_title\"]\n","triplet_from_target = np_arr_target[np_arr_target[:,1] == \"http://erlangen-crm.org/current/P102_has_title\"]\n","# TO DO!!!\n","# select all subject which have MULTIPLE propertys in common\n"],"metadata":{"id":"FTQl7rBX8A02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prod_obj = itertools.product(triplet_from_source[:,2], triplet_from_target[:,2])\n","prod_obj = np.array([x for x in prod_obj])\n","np.shape(prod_obj)\n","### \n","prod_subj = itertools.product(triplet_from_source[:,0], triplet_from_target[:,0])\n","prod_subj = np.array([x for x in prod_subj])\n"],"metadata":{"id":"waJGcarvlDdx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Comparaison levenshtein Methode Gloutonne\n"],"metadata":{"id":"7HqJTiMm2IHF"}},{"cell_type":"code","source":["g = lambda x,y : td.levenshtein(x,y)"],"metadata":{"id":"qvI0VcfJmzEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# WARNING Execution longue (peut prendre plusieurs minutes)\n","mapp = np.zeros((np.shape(prod_obj)[0],1))\n","for i in range(mapp.shape[0]):\n","  mapp[i] = g(prod_obj[i,0],prod_obj[i,1])"],"metadata":{"id":"QiYvfo00mV1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seuil = 2"],"metadata":{"id":"EbjyRf8E1AKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask = mapp<seuil\n","mask = mask.flatten()\n","mask_idx = [i for i in range(np.shape(prod_obj)[0]) if mask[i]]\n","print(\"Nb element: \", len(mask_idx))"],"metadata":{"id":"_KVpz2vIsycC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prod_subj[mask]"],"metadata":{"id":"PMCSeGzAzukO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LevenshteinNormalized Similarity\n","g = lambda x,y : 1 - td.levenshtein(x,y)/max(len(x),len(y))"],"metadata":{"id":"rxlditmi3fZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LevenshteinNormalized Similarity\n","mapp = np.zeros((np.shape(prod_obj)[0],1))\n","for i in range(mapp.shape[0]):\n","  mapp[i] = g(prod_obj[i,0],prod_obj[i,1])"],"metadata":{"id":"US90efJ73DmC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ngram = lambda x,y : "],"metadata":{"id":"a5JkvFIg3mJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Partie Verité Terrain"],"metadata":{"id":"G3bS-RgCbgyz"}},{"cell_type":"code","source":["from xml.dom.minidom import parse\n","DOMTree = parse('veriteTerrain.xml')\n"],"metadata":{"id":"ZjU0-a3tAVKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collection = DOMTree.documentElement\n","\n","uriSource = collection.getElementsByTagName('entity1')\n","uriTarget = collection.getElementsByTagName('entity2')\n","\n","verite_terrain = list()\n","for uriS,uriT in zip(uriSource,uriTarget):\n","  verite_terrain.append([uriS.getAttribute('rdf:resource'),uriT.getAttribute('rdf:resource')])\n","\n","verite_terrain = np.array(verite_terrain).astype(\"str\")"],"metadata":{"id":"C0Vm-S6hCXC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["verite_terrain[:,1]"],"metadata":{"id":"NqHzIxGYDKz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["obj_1 = []\n","obj_2 = []\n","\n","for subj1 in verite_terrain[:,0]:\n","  obj_1.append(np_arr_source[np_arr_source[:,0] == subj1][:,2])\n","\n","\n","for subj2 in verite_terrain[:,1]:\n","  obj_2.append(np_arr_target[np_arr_target[:,0] == subj2][:,2])\n","\n","for i in range(5):\n","  print(obj_1[i])\n","  print(\"\\n\")\n","  print(obj_2[i])\n","  print(\"\\n\\n\\n\\n\\n\")\n"],"metadata":{"id":"yfpFz0abK8yX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation **Resultats**"],"metadata":{"id":"17FmZ7OGJ2mj"}},{"cell_type":"code","source":["# total de couples trouvés\n","len(prod_subj[mask][:,0])"],"metadata":{"id":"urWg8N18M2WK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# couples qui sont veritablement à relié parmi ceux trouvés par notre algo\n","common = np.intersect1d(prod_subj[mask][:,0],verite_terrain[:,0])\n","len(common)"],"metadata":{"id":"ndi9ksb3Nn-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prod_subj[mask]\n","verite_terrain\n"],"metadata":{"id":"QDiiuFqhOtQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["uriSource = 'http://data.doremus.org/expression/ecc9da64-422b-3a47-8b07-4bb3c2ff4f1e'"],"metadata":{"id":"9x7hqZltRAe2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["verite_terrain[verite_terrain[:,0] == uriSource]"],"metadata":{"id":"_oGqyK7qP3ji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx = [i for i in range(len(verite_terrain[:,0])) if verite_terrain[:,0][i] in common]\n","\n","count = 0\n","for uriSource,uriTarget in verite_terrain[idx,:]:\n","  if (prod_subj[mask][prod_subj[mask][:,0] == uriSource].flatten()[1]) == (verite_terrain[verite_terrain[:,0] == uriSource].flatten()[1]):\n","    count+=1\n","count"],"metadata":{"id":"3m3JoPozJ5F_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Il y'a 238 couples uri qui sont à reliés Parmi les 210 trouvés dans cet exemple 152 sont véritablement à relié. Notre algo à réussi à bien relier 151 d'entres eux et s'est trompé pour un"],"metadata":{"id":"Pu5o8Tw_Mp3E"}},{"cell_type":"code","source":["print(\"precision\")\n","precision = 151/152"],"metadata":{"id":"Uj1HUNtYTpXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"recall\")\n","recall = 152/238"],"metadata":{"id":"u2zhvmGHTsGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"F measure\")\n","2*(precision*recall)/(precision+recall)"],"metadata":{"id":"my-ce4GTT1Ed"},"execution_count":null,"outputs":[]}]}